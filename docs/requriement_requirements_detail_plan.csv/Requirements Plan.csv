id,req_id,category,formalized_text,feature_group,original_text,assumptions,constraints,dependencies,detail_analysis,priority,validation_criteria
1913,REQ-CSVC-001,Functional,"The OPC client library/service shall support communication using OPC Data Access (DA) versions 2.05a and 3.0, OPC Unified Architecture (UA) version 1.04 and higher (including relevant companion specifications as applicable), and OPC XML-DA version 1.01 for real-time data exchange. The client shall handle diverse data types and structures as defined by these standards.",Core OPC Client Services,"Supports OPC DA (versions 2.05a and 3.0), OPC UA (version 1.04 and higher, including relevant companion specifications as applicable), and OPC XML-DA (version 1.01), handling diverse data types and structures. Ensures compatibility with servers from manufacturers like Siemens or Rockwell.",,,,FALSE,high,
1914,REQ-CSVC-002,Functional,"The OPC client library/service shall provide functionality to browse the address space (namespace) of connected OPC DA and OPC UA servers, enabling discovery of available tags and server structure.",Core OPC Client Services,Allows users to browse server namespaces...,,,,FALSE,high,
1915,REQ-CSVC-003,Functional,"The OPC client library/service shall enable applications to read the current values, timestamps, and quality of specified tags from connected OPC DA and OPC UA servers.",Core OPC Client Services,...read current tag values...,,,,FALSE,high,
1916,REQ-CSVC-004,Functional,The OPC client library/service shall enable applications to write values to specified tags on connected OPC DA and OPC UA servers.,Core OPC Client Services,...and write updates.,,,,FALSE,high,
1917,REQ-CSVC-005,NonFunctional,The OPC client library/service shall achieve a P99 latency of less than 50ms for typical synchronous read and write operations to OPC servers under defined load conditions.,Core OPC Client Services,"Ensures low-latency communication for time-critical applications, with target read/write latency of less than 50ms (P99) for typical operations.",,,,FALSE,high,
1918,REQ-CSVC-006,Functional,"The OPC client library/service shall implement robust error handling for read and write operations, providing clear status codes and descriptive messages to the calling application for failures such as communication timeouts, connection loss, invalid tag addresses, or access denied.",Core OPC Client Services,"Error handling for failed read/write operations (e.g., communication timeouts, connection loss, invalid tag address) will be implemented, providing clear status codes and messages to the calling application or UI.",,,,FALSE,high,
1919,REQ-CSVC-007,Functional,"The OPC client library/service shall support configurable client-side data validation rules (e.g., range checks, data type checks) for write operations before sending data to the OPC server. The system shall provide feedback if validation fails.",Core OPC Client Services,"Data validation rules for write operations (e.g., range checks, type checks if configurable by user) will be supported.",,,,FALSE,medium,
1920,REQ-CSVC-008,Functional,"The system shall provide a mechanism to import tag configurations (including tag lists, server addresses, item IDs, and scaling parameters) from common file formats (e.g., CSV, XML). The system shall validate imported configurations for correctness and completeness.",Core OPC Client Services,"A mechanism for importing existing tag configurations (e.g., tag lists, addresses, scaling parameters) from common legacy OPC client formats or spreadsheets will be provided to expedite setup. Validation of imported configurations will be performed.",,,,FALSE,medium,
1921,REQ-CSVC-009,Functional,"The system shall log all write operations to designated critical control system tags. Each log entry must include user credentials (if available from the calling context), timestamp of the operation, the tag identifier, the old value (if retrievable), and the new value written. This logging must support audit trail requirements for regulations like FDA 21 CFR Part 11.",Core OPC Client Services,"All write operations to critical control system tags must be logged with user credentials, timestamp, old value, and new value for audit trail purposes, in compliance with relevant industry regulations (e.g., FDA 21 CFR Part 11 for pharmaceutical applications).",,,,FALSE,high,
1922,REQ-CSVC-010,Functional,"The system shall support configurable limits on data write operations, including rate limits (number of writes per unit of time to a tag/server) and value change thresholds that may require secondary confirmation before the write is executed. These limits shall be configurable based on organizational policies.",Core OPC Client Services,"Configurable limits on data write operations (e.g., rate limits, value change thresholds requiring secondary confirmation) may be implemented based on organizational safety and operational policies.",,,,FALSE,medium,
1923,REQ-CSVC-011,Functional,The OPC client library/service shall implement the OPC Historical Data Access (HDA) specification to retrieve historical data from compliant OPC HDA servers. This includes supporting queries for processed or raw data over specified time ranges.,Core OPC Client Services,"Implements the OPC Historical Access specification, supporting queries over specific time ranges.",,,,FALSE,high,
1924,REQ-CSVC-012,Functional,"The OPC client library/service, when querying OPC HDA servers, shall support requesting various data aggregation functions as defined by the OPC HDA specification. Supported functions must include average, minimum, maximum, count, range, total, and standard interpolation types (e.g., linear, stepped). The service shall also support filtering criteria as per OPC HDA for historical data queries.",Core OPC Client Services,"Includes data aggregation, filtering, and trend visualization tools. Supported data aggregation functions will include, but are not limited to, average, minimum, maximum, count, range, total, and various interpolation types (e.g., linear, stepped).",,,,FALSE,high,
1925,REQ-CSVC-013,Functional,"The OPC client system shall be capable of providing retrieved historical data (conforming to a defined model: timestamp, tag identifier, value, quality, metadata) for ingestion into a designated time-series database. This data provision shall support optimized batching or streaming and include configurable validation rules (e.g., timestamp sanity checks, value range checks) before data is passed for ingestion.",Core OPC Client Services,Historical data and alarm/event logs will be stored in a suitable time-series database... Data ingestion into the time-series database will be handled via optimized batching mechanisms or streaming connectors... with configurable data validation rules...,,,,FALSE,high,
1926,REQ-CSVC-014,NonFunctional,"The OPC client library/service, when interacting with an OPC HDA server, shall facilitate historical data queries such that retrieving a 1-day time range of data for 100 tags completes in less than 2 seconds (P95), assuming adequate OPC HDA server and network performance.",Core OPC Client Services,"Query response times for a 1-day range of 100 tags should be less than 2 seconds, utilizing native query languages like Flux for InfluxDB or SQL for TimescaleDB.",,,,FALSE,high,
1927,REQ-CSVC-015,Functional,"The OPC client library/service shall implement error handling for OPC HDA queries, providing clear status codes and descriptive messages to the calling application for failures such as data not found for the specified range, query timeout, or invalid aggregation parameters.",Core OPC Client Services,"Error handling for HDA queries (e.g., data not found for the specified range, query timeout, invalid aggregation parameters) will provide informative feedback.",,,,FALSE,high,
1928,REQ-CSVC-016,Functional,"The system shall provide capabilities or documented procedures and tools to support the migration of existing historical data from other systems (e.g., proprietary historians, SQL databases) into the system's designated time-series database. This includes support for data extraction, transformation (e.g., timestamp normalization, tag mapping, unit conversion), loading, and validation of migrated data.",Core OPC Client Services,"For customers with existing historical data in other systems... a comprehensive data migration plan will be developed. This includes defining procedures for data extraction, transformation... loading... and rigorous validation...",,,,FALSE,medium,
1929,REQ-CSVC-017,Functional,The OPC client library/service shall support the OPC Alarms and Conditions (A&C) specification for receiving and managing alarm and event notifications from OPC A&C servers. This includes enabling client applications to interact with alarm states such as prioritization and suppression.,Core OPC Client Services,"Supports the OPC Alarms and Conditions specification, enabling prioritization, suppression, and logging of alerts.",,,,FALSE,high,
1930,REQ-CSVC-018,Functional,"The OPC client library/service shall support alarm acknowledgement operations as defined by the OPC A&C specification. Received alarm records must contain at least: timestamp of occurrence, source node, event type, severity, condition name, message, acknowledged state, and timestamp of acknowledgment/return-to-normal. The service must support passing user identification and acknowledgement comments if provided by the calling application.",Core OPC Client Services,"Provides a user interface for acknowledging alarms. Alarm records will include at least: timestamp of occurrence, source node, event type, severity, condition name, message, acknowledged state, and timestamp of acknowledgment/return-to-normal.",,,,FALSE,high,
1931,REQ-CSVC-019,Functional,The OPC client system shall be capable of providing received alarm and event data for ingestion into a designated time-series database. Incoming alarm and event data from OPC A&C servers shall be validated by the client service to ensure required fields (as per REQ-CSVC-018) are present before provision for storage.,Core OPC Client Services,"Alarm and event data will be stored in a time-series database... Data validation rules for incoming alarm and event data (e.g., ensuring required fields are present) will be implemented.",,,,FALSE,high,
1932,REQ-CSVC-020,Functional,"The OPC client service shall generate distinct events or messages for alarms that can be consumed by higher-level system components to trigger configurable notification mechanisms (e.g., UI alerts, email, SMS) and to implement configurable alarm escalation policies for unacknowledged critical alarms.",Core OPC Client Services,The system will support configurable notification mechanisms for alarms... The system will support configurable alarm escalation policies for unacknowledged critical alarms.,,,,FALSE,high,
1933,REQ-CSVC-021,Functional,"The system shall ensure that all alarm lifecycle changes managed or initiated through the OPC client (e.g., acknowledgements, suppressions requested by the client) are auditable. This may involve the client service providing necessary data to a centralized audit logging mechanism.",Core OPC Client Services,"An audit trail will be maintained for all alarm lifecycle changes, including acknowledgments, suppressions, and configuration modifications.",,,,FALSE,high,
1934,REQ-CSVC-022,Functional,The system shall provide capabilities or documented procedures and tools to support the migration of existing alarm and event logs from legacy systems into the system's designated time-series database. This includes support for schema mapping and validation of migrated A&E data.,Core OPC Client Services,"Procedures for migrating existing alarm and event logs from legacy systems into the new time-series database will be defined, including schema mapping and validation, to ensure continuity of historical alarm analysis.",,,,FALSE,medium,
1935,REQ-CSVC-023,Functional,"The OPC client library/service shall support OPC UA subscriptions to monitored items for receiving real-time data changes and event notifications from OPC UA servers, reducing polling overhead. The service shall allow configuration of subscription parameters, including sampling interval, publishing interval, queue size, and deadbands for monitored items.",Core OPC Client Services,"Supports monitored items and notifications, reducing polling overhead. Configurable update rates for efficiency.",,,,FALSE,high,
1936,REQ-CSVC-024,NonFunctional,"The OPC client library/service shall ensure that subscription update notifications are delivered from the OPC UA server to the client application logic with a P99 latency of less than 100ms, under defined load conditions.",Core OPC Client Services,Subscription update delivery time should be less than 100ms (P99) from server to client application.,,,,FALSE,high,
1937,REQ-CSVC-025,Functional,"The OPC client library/service shall support OPC UA subscriptions over standard transport protocols, including OPC UA TCP (binary) and WebSockets with PubSub (using JSON or UADP encoding as specified by OPC UA standards).",Core OPC Client Services,"Underlying transport protocols for OPC UA subscriptions (e.g., OPC UA TCP, WebSockets with PubSub using JSON or UADP encoding) will be supported.",,,,FALSE,high,
1938,REQ-CSVC-026,Functional,"The OPC client library/service shall automatically detect subscription loss (e.g., due to network issues, server restart) and attempt to re-establish lost subscriptions. The service shall support client-side buffering of critical subscription data during short interruptions (configurable duration) to prevent data loss, and perform data integrity checks on buffered data upon successful re-establishment.",Core OPC Client Services,"Clear mechanisms will be in place for handling subscription loss (e.g., due to network issues or server restart) and automatically attempting re-establishment, including buffering of critical subscription data on the client-side where feasible to prevent data loss during short interruptions. Data integrity checks for buffered data upon re-establishment will be performed.",,,,FALSE,high,
1939,REQ-CSVC-027,Functional,"The system shall provide a mechanism or documented procedure to import existing subscription configurations (including monitored items, update rates, deadbands) from common legacy OPC client formats or spreadsheets, where feasible, to minimize reconfiguration effort.",Core OPC Client Services,"A method for migrating existing subscription configurations (monitored items, update rates, deadbands) from legacy OPC clients will be provided, where feasible, to minimize reconfiguration effort.",,,,FALSE,medium,
1940,REQ-CSVC-028,Functional,"The OPC client service shall provide status information regarding the health of subscriptions, including explicit indication of critical subscription loss, enabling higher-level system components to trigger alerts to operators or system administrators as per defined notification policies.",Core OPC Client Services,Loss of critical subscriptions must trigger an alert to operators or system administrators as per defined notification policies.,,,,FALSE,high,
1941,REQ-SAP-001,Technical,"The system MUST implement a hybrid architecture consisting of a core OPC client library/service and a separate server-side application. The core OPC client library/service MUST be developed using .NET 6 (or a later version) and MUST support cross-platform deployment on Windows, Linux, and macOS.",System Architecture & Platform,"The system will be built upon a hybrid architecture. This includes a core OPC client library/service developed using .NET 6+ for cross-platform compatibility (Windows, Linux, macOS).",,,,FALSE,high,
1942,REQ-SAP-002,Functional,"The server-side application MUST be developed using ASP.NET Core and MUST provide functionalities for centralized management, backend AI processing, and automated reporting services. It MUST also serve the web-based User Interface and expose RESTful APIs or gRPC endpoints for inter-service and external client communication.",System Architecture & Platform,"For advanced functionalities, a separate server-side application (e.g., built with ASP.NET Core using RESTful APIs or gRPC for inter-service communication [Essential for defining how different parts of the system and external clients interact with the backend]) will support centralized management, backend AI processing, automated reporting services, and will serve a web-based User Interface.",,,,FALSE,high,
1943,REQ-SAP-003,Technical,"The system MUST utilize gRPC for synchronous request/response interactions and message queues (e.g., RabbitMQ, Kafka) for asynchronous eventing between the core OPC client library/service and the server-side application. These communication protocols MUST be implemented to be efficient and secure.",System Architecture & Platform,"Communication between the core library/service and the server-side application will utilize efficient and secure protocols like gRPC or message queues (e.g., RabbitMQ, Kafka) depending on the interaction pattern (e.g., synchronous request/response vs. asynchronous eventing) [Essential for defining the internal system architecture and ensuring efficient, secure communication between components].",,,,FALSE,high,
1944,REQ-SAP-004,Technical,The system MUST use Protocol Buffers (Protobuf) as the data serialization format for all gRPC-based communication. JSON MUST be used as the data serialization format for all RESTful API communication.,System Architecture & Platform,Data serialization formats such as Protocol Buffers (Protobuf) for gRPC and JSON for RESTful APIs will be utilized.,,,,FALSE,high,
1945,REQ-SAP-005,Technical,"The system design documentation MUST include clearly defined data models for all inter-service communication. This includes message schemas for message queues and contract definitions (e.g., OpenAPI specifications for REST APIs, .proto files for gRPC) for all exposed APIs.",System Architecture & Platform,"Data models for inter-service communication, including message schemas for queues and contract definitions for APIs, will be clearly defined.",,,,FALSE,high,
1946,REQ-SAP-006,NonFunctional,"The system architecture MUST be modular, logically separating the core OPC client library/service, the server-side application, and its primary functional components (e.g., management, AI processing, reporting, UI services) to support independent scalability and enhance overall system maintainability.",System Architecture & Platform,This modular design ensures scalability and maintainability.,,,,FALSE,high,
1947,REQ-SAP-007,Technical,"The system's deployment methodology MUST support a phased rollout, enabling initial deployment and operation of core OPC client functionalities, followed by the incremental deployment of server-side components and subsequently advanced features.",System Architecture & Platform,"Deployment will follow a phased approach, potentially starting with core client functionalities followed by server-side components and advanced features.",,,,FALSE,medium,
1948,REQ-SAP-008,Technical,"The project execution plan MUST incorporate a pilot program conducted at selected customer sites. This program's objective is to validate the system architecture, core functionalities, and performance in a representative real-world industrial automation environment prior to wider deployment.",System Architecture & Platform,A pilot program with selected customer sites may be utilized to validate the architecture in a real-world environment before broader rollout.,,,,FALSE,medium,
1949,REQ-SAP-009,Functional,"The system MUST provide a documented strategy, and may include supporting tools or scripts, for migrating client configurations from common existing OPC client solutions to the new system's configuration database. This strategy MUST detail data mapping, transformation logic (if required), and procedures for validating migrated configurations.",System Architecture & Platform,"For customers transitioning from existing OPC client solutions, a strategy for migrating client configurations (e.g., server connection details, initial tag sets) to the new system's configuration database will be provided. This includes defining data mapping, transformation logic if needed, and validation procedures.",,,,FALSE,high,
1950,REQ-SAP-010,NonFunctional,The system MUST be designed to coexist and operate concurrently with existing legacy OPC client instances during a phased rollout period. This coexistence MUST NOT cause disruption to critical industrial operations reliant on these legacy clients or the shared OPC servers.,System Architecture & Platform,"During the transition period, the system must coexist with legacy OPC client instances if a phased rollout is adopted, ensuring no disruption to critical operations.",,,,FALSE,high,
1951,REQ-SAP-011,Technical,"The project deliverables MUST include clear, documented plans and procedures for the eventual and safe decommissioning of legacy OPC client systems that are replaced by the new system.",System Architecture & Platform,Clear plans for the eventual decommissioning of replaced legacy systems will be established.,,,,FALSE,medium,
1952,REQ-SAP-012,NonFunctional,"The system's design, development, deployment, and operational processes MUST adhere to the customer organization's documented existing enterprise architecture standards and IT governance policies applicable to new system deployments.",System Architecture & Platform,Adherence to the organization's existing enterprise architecture standards and IT governance policies for new system deployments must be ensured.,,,,FALSE,high,
1953,REQ-SAP-013,NonFunctional,"The official system documentation MUST clearly specify the minimum supported versions for each target operating system, including Windows (e.g., Windows 10, Windows Server 2016 or later), specific Linux distributions (e.g., Ubuntu LTS, RHEL), and macOS versions.",System Architecture & Platform,"Minimum supported OS versions will be documented (e.g., Windows 10 / Server 2016+, specific Linux distributions like Ubuntu LTS, RHEL, and macOS versions).",,,,FALSE,high,
1954,REQ-SAP-014,NonFunctional,"The official system documentation MUST provide typical resource requirements (CPU, RAM, disk space, network bandwidth) for both core OPC client instances and server-side application components. These requirements MUST be detailed for different deployment scales (e.g., small, medium, large, or based on tag count/user load).",System Architecture & Platform,"Typical resource requirements (CPU, RAM, disk space, network bandwidth) for client instances and server components will be provided for different deployment scales and documented.",,,,FALSE,high,
1955,REQ-SAP-015,Technical,"The system architecture MUST support hybrid cloud deployment models. This includes the capability for client management, backend AI processing, and other server-side application components to run in a cloud environment, while the core OPC client instance (deployable in a VM or container) operates on-premises and connects to local OPC servers.",System Architecture & Platform,"Cloud deployment models will be supported, allowing client management and AI components to run in the cloud, while the OPC client instance (potentially in a VM or container) connects to on-premises OPC servers...",,,,FALSE,high,
1956,REQ-SAP-016,Technical,"In hybrid cloud deployment models, all communication between on-premises OPC client instances and cloud-hosted server-side components MUST be conducted over a secure channel. The system or its deployment guide MUST support or recommend configurations for establishing such secure channels (e.g., site-to-site VPN, Azure ExpressRoute, AWS Direct Connect, or secure tunneling protocols like WireGuard/OpenVPN).",System Architecture & Platform,"...via a secure channel (e.g., site-to-site VPN, Azure ExpressRoute, AWS Direct Connect, or secure tunneling protocols like WireGuard/OpenVPN [Critical for secure hybrid cloud deployments]).",,,,FALSE,high,
1957,REQ-SAP-017,Technical,"The system components, including the core OPC client library/service and modules of the server-side application, MUST be deployable using Docker containers. Official Docker images or comprehensive build scripts for creating these images MUST be provided.",System Architecture & Platform,Docker will be recommended for containerization...,,,,FALSE,high,
1958,REQ-SAP-018,Technical,"The system's containerized components MUST be designed for compatibility with container orchestration platforms such as Kubernetes or Docker Swarm. For Kubernetes, deployment guides, manifests, or Helm charts SHOULD be provided to facilitate orchestration, particularly for larger deployments or microservice elements of the server-side application.",System Architecture & Platform,...with considerations for Kubernetes or Docker Swarm for orchestration in larger deployments or microservice-based components.,,,,FALSE,medium,
1959,REQ-SAP-019,Technical,"The project MUST provide Infrastructure as Code (IaC) scripts or templates, using tools such as Terraform, Pulumi, Azure Bicep/ARM Templates, or AWS CloudFormation, to enable automated, repeatable, and manageable provisioning of the system's required cloud-based infrastructure components.",System Architecture & Platform,"Infrastructure as Code (IaC) tools (e.g., Terraform, Pulumi, Bicep/ARM Templates, CloudFormation) will be utilized for managing and provisioning cloud deployments [Ensures repeatable and manageable cloud infrastructure provisioning].",,,,FALSE,high,
1960,REQ-SAP-020,Technical,"As part of the implementation process, pilot deployments of the core OPC client library/service MUST be conducted on each supported target operating system (Windows, Linux, macOS) within the customer's specific IT environment. These pilots aim to validate platform-specific dependencies, integration, and performance characteristics.",System Architecture & Platform,A pilot deployment on each target operating system within the customer's environment will be conducted to validate platform-specific dependencies and performance.,,,,FALSE,medium,
1961,REQ-SAP-021,Technical,"The provided Infrastructure as Code (IaC) templates for cloud deployments MUST be designed to be customizable to accommodate specific customer cloud subscription details, existing networking topology, and security policies.",System Architecture & Platform,"For cloud deployments, IaC templates will be customized to fit the customer's cloud subscription and networking topology.",,,,FALSE,medium,
1962,REQ-SAP-022,Technical,"The project MUST provide documented, detailed cutover plans for scenarios involving the migration of OPC client instances from one operating system to another (e.g., Windows to Linux). These plans MUST include procedures for secure configuration transfer, comprehensive pre- and post-migration testing, and clearly defined rollback mechanisms.",System Architecture & Platform,"If migrating client instances between operating systems (e.g., from an old Windows-based client to a new Linux-based instance), detailed cutover plans including configuration transfer, testing, and rollback procedures are required.",,,,FALSE,medium,
1963,REQ-SAP-023,NonFunctional,"All system deployments, whether on-premises or in the cloud, MUST comply with the customer's documented organizational IT infrastructure standards. This includes adherence to approved operating system versions, security patching levels, and any applicable containerization policies.",System Architecture & Platform,"All deployments must comply with the customer's organizational IT infrastructure standards, including approved OS versions, patching levels, and containerization policies.",,,,FALSE,high,
1964,REQ-SAP-024,NonFunctional,"The actual system resources (CPU, RAM, disk, network) allocated for deployed core OPC client instances and server-side application components MUST align with the officially documented resource requirements for the intended scale and load. The system or associated monitoring tools MUST facilitate monitoring of these allocated resources to help ensure that performance Service Level Agreements (SLAs) are consistently met.",System Architecture & Platform,Resource allocation for client instances and server components must align with documented requirements and be monitored to ensure performance SLAs are met.,,,,FALSE,high,
1965,REQ-3-001,Functional,"The system shall implement OPC UA standard security mechanisms, including certificate-based authentication, message signing, user authentication as per OPC UA specifications, and 128/256-bit encryption for all OPC UA communication.",Security & Access Control,"Implements certificate-based authentication, 128/256-bit encryption (e.g., AES-256 for data at rest), message signing, and user authentication per OPC UA standards.",,,,FALSE,high,
1966,REQ-3-002,NonFunctional,"The system shall encrypt all sensitive data at rest, including user configurations, designated sensitive data in relational databases, alarm/event logs, and historical process values in specialized databases, using AES-256 or an equivalently strong encryption algorithm.",Security & Access Control,"AES-256 for data at rest...User configurations and other specifically designated sensitive data will be stored using a relational database...with appropriate security measures including encryption at rest. Other categories of data that may be sensitive, such as alarm/event logs or historical process values, will be stored in their respective specialized databases...with security measures equivalent...ensuring consistent and robust security across all data stores handling sensitive information.",,,,FALSE,high,
1967,REQ-3-003,Functional,"The system shall implement a Role-Based Access Control (RBAC) mechanism to govern access to system functionalities and data. It shall provide predefined, customizable roles (e.g., Administrator, Engineer, Operator, Viewer) with defined permission sets. All user and role management actions shall be logged.",Security & Access Control,"Supports role-based access control (RBAC)...The system will provide a set of predefined default roles (e.g., Administrator, Engineer, Operator, Viewer) with typical permission sets, which can be customized. The data model for user roles and permissions will be defined. All user management actions (creation, deletion, role changes, permission modifications) will be logged in an audit trail.",,,,FALSE,high,
1968,REQ-3-004,Functional,"The system shall support integration with external Identity Providers (IdPs) such as Keycloak, Azure AD, or Okta, using OAuth 2.0/OpenID Connect protocols for user authentication and authorization to the web UI and APIs. Configuration shall allow defining scopes, claims, and redirect URIs.",Security & Access Control,"potentially integrated with an Identity Provider (IdP) using OAuth 2.0/OpenID Connect (e.g., Keycloak, Azure AD, Okta) for managing user identities and access to the web UI and APIs. Integration with an existing corporate IdP will require collaborative planning...including defining scopes, claims, and redirect URIs. A pilot integration phase is recommended.",,,,FALSE,high,
1969,REQ-3-005,Functional,"The system shall provide an internal user management system with configurable password policies, including minimum length, complexity requirements (e.g., uppercase, lowercase, numbers, symbols), password history enforcement, and account lockout after multiple failed attempts, if an external IdP is not used or used in conjunction.",Security & Access Control,"If an internal user management system is utilized...it will enforce configurable password policies (e.g., complexity, length, history, expiration).",,,,FALSE,high,
1970,REQ-3-006,NonFunctional,"The system shall implement secure cryptographic key management procedures for all keys used (e.g., for data encryption, message signing), including cryptographically secure generation, secure storage (e.g., HSM, secure vault), periodic rotation, and timely revocation, adhering to industry best practices.",Security & Access Control,"Key management procedures will be established for managing cryptographic keys, including generation, storage, rotation, and revocation, adhering to industry best practices.",,,,FALSE,high,
1971,REQ-3-007,NonFunctional,"The system shall employ secure credential management for its internal components and communications with external services, utilizing mechanisms such as Hardware Security Modules (HSMs) where appropriate, or managed identity services (e.g., Azure Managed Identities, AWS IAM Roles) for cloud-deployed resources, avoiding hardcoded credentials.",Security & Access Control,"Additionally, the system will incorporate secure credential management (e.g., using hardware security modules where appropriate, or managed identity services like Azure Managed Identities or AWS IAM Roles for cloud resources)",,,,FALSE,high,
1972,REQ-3-008,Functional,"The system shall ensure the integrity of AI models (e.g., through checksums, digital signatures) to prevent unauthorized modification and implement access controls to manage deployment, configuration, and interaction with AI models and their outputs based on user roles.",Security & Access Control,ensure AI model integrity and implement access controls for AI models,,,,FALSE,medium,
1973,REQ-3-009,NonFunctional,"The system shall ensure end-to-end encryption using strong, current cryptographic protocols (e.g., TLS 1.2+ with strong cipher suites) for all communications between client instances/users and the centralized management interface.",Security & Access Control,provide end-to-end encryption for communications with the centralized management interface.,,,,FALSE,high,
1974,REQ-3-010,Functional,"The system's server-side application endpoints (e.g., RESTful APIs, gRPC services) shall be protected using robust authentication methods, such as JSON Web Tokens (JWT) with proper validation (signature, expiry, audience) or securely managed API Keys.",Security & Access Control,"Secure API authentication methods (e.g., JWT, API Keys) will be used for server-side application endpoints [Essential for protecting backend services].",,,,FALSE,high,
1975,REQ-3-011,NonFunctional,"The system shall be designed to support and facilitate regular security audits. It must provide mechanisms for designated personnel to review and audit access rights, security configurations (including firewall rules for inter-service communication), and compliance with security policies periodically.",Security & Access Control,"Regular security audits will be mandated. Access rights and security configurations (including firewall rules for service communication) must be reviewed and audited periodically (e.g., quarterly or annually) by designated security personnel, in line with organizational policy.",,,,FALSE,medium,
1976,REQ-3-012,Functional,"The system shall implement comprehensive and immutable audit logging to capture security-relevant events. This includes, but is not limited to, successful and failed login attempts, authorization changes (e.g., role assignments, permission modifications), administrative actions (e.g., system configuration changes), and access to data classified as sensitive. Logs must include timestamp, user identity, action performed, outcome, and relevant resource identifiers.",Security & Access Control,"Comprehensive audit logging will capture security-relevant events, including login attempts (successful and failed), authorization changes, administrative actions, and access to sensitive data.",,,,FALSE,high,
1977,REQ-3-013,Functional,"The system shall support data classification (e.g., Confidential, Restricted, Internal, Public) for data it manages. Appropriate protection mechanisms, such as access controls and encryption, shall be applied based on these classifications, ensuring least privilege access.",Security & Access Control,"Data will be classified (e.g., Confidential, Restricted, Internal, Public), and protection mechanisms will be applied accordingly.",,,,FALSE,medium,
1978,REQ-3-014,Functional,"The system shall be designed to facilitate compliance with applicable data privacy regulations (e.g., GDPR, CCPA). It must provide documented procedures and, where feasible, tools to support Data Subject Access Requests (DSARs), including the right to access, rectify, and request erasure or anonymization of personal data stored within its user management system and relevant audit logs, subject to legal retention requirements.",Security & Access Control,"Compliance with relevant data privacy regulations (e.g., GDPR, CCPA...)...The system must provide mechanisms to support data subject access requests (DSAR) and the right to erasure/anonymization for personal data stored within its user management or audit log components, as mandated by GDPR/CCPA.",,,,FALSE,high,
1979,REQ-3-015,Functional,"The system shall provide capabilities for data masking or anonymization of sensitive data. This functionality should be available for use in non-production environments (e.g., development, testing) or for specific use cases requiring de-identified data, ensuring that original sensitive information is not exposed.",Security & Access Control,"Where applicable for non-production environments or specific use cases, data masking or anonymization techniques will be available for sensitive data.",,,,FALSE,medium,
1980,REQ-3-016,Technical,"The system shall support or provide documented strategies for user data migration. This includes mapping existing user accounts and permissions to IdP identities when transitioning to an IdP, and defining processes for secure migration of user credentials (if compliant) or a mandatory password reset process when transitioning between internal user management systems.",Security & Access Control,"If migrating from a system with local user management to an IdP-integrated solution, a strategy for mapping existing user accounts and permissions to IdP identities will be required. For transitions between internal user management systems, secure migration of user credentials (if possible and compliant) or a password reset process will be defined.",,,,FALSE,medium,
1981,REQ-3-017,NonFunctional,"The solution shall include provisions for security-focused training materials and documentation. Administrator training materials shall cover RBAC management, IdP integration procedures, certificate lifecycle management, and interpretation of security audit logs. User training materials shall cover secure login procedures, password management best practices, and awareness of social engineering threats.",Security & Access Control,"Administrators will require training on managing RBAC, IdP integration, certificate management, and interpreting security audit logs. Users will be trained on secure login procedures and password policies.",,,,FALSE,medium,
1982,REQ-3-018,NonFunctional,The system's operational documentation and recommended procedures shall require that all detected security incidents or vulnerabilities related to the OPC client system are reported and managed in accordance with the customer organization's established incident response plan. The system should facilitate this by providing relevant logs and diagnostic information.,Security & Access Control,All security incidents or detected vulnerabilities must be reported and managed according to the organization's established incident response plan.,,,,FALSE,high,
1983,REQ-UIX-001,NonFunctional,"The system shall provide an intuitive Graphical User Interface (GUI) for configuration and monitoring.
The UI technology shall support cross-platform deployment.
Web-based UI components shall adhere to WCAG 2.1 Level AA accessibility standards; desktop UI (if any) shall adhere to platform-specific accessibility guidelines.
Both web and desktop UIs shall support comprehensive keyboard navigation and screen reader compatibility.
The UI shall be responsive, adapting to screen sizes from standard desktop monitors to tablet displays.
The UI shall integrate user feedback mechanisms: progress indicators, success/error messages, and contextual help.",User Interface & Experience (UI/UX),"Offers an intuitive GUI for configuration and monitoring. The UI technology will be chosen to support cross-platform deployment and accessibility. The interface will adhere to WCAG 2.1 Level AA accessibility standards for web-based components and platform-specific accessibility guidelines for desktop applications, including comprehensive keyboard navigation and screen reader compatibility. The UI will be designed for responsiveness across various screen sizes and resolutions, from standard desktop monitors to tablet displays. User feedback mechanisms, such as progress indicators, success/error messages, and contextual help, will be integrated throughout the UI.",,,,FALSE,high,
1984,REQ-UIX-002,Functional,"The system shall provide a web-based UI, recommended to be built with Blazor WebAssembly and served by the .NET backend, for accessibility and centralized management.
This web UI must provide comprehensive client configuration capabilities (e.g., tag configuration, namespace browsing) adapted for a web environment.
The web UI shall enable full management of all OPC client instances, including headless ones.
A suitable state management solution shall be employed for the web UI to manage complexity and maintainability.",User Interface & Experience (UI/UX),"For broader accessibility and centralized management, a web-based UI using Blazor WebAssembly served by the .NET backend is recommended; this web-based interface must incorporate comprehensive client configuration capabilities, including functionalities equivalent to 'tag configuration' and 'namespace browsing' (adapted for a web environment), to ensure full management of all client instances, including headless ones. State management solutions (e.g., Blazor's built-in mechanisms, or Redux/NgRx if a JavaScript framework is chosen) will be employed for complex UIs.",,,,FALSE,high,
1985,REQ-UIX-003,Functional,"If desktop applications are developed for local client interaction, they shall utilize cross-platform frameworks such as Avalonia UI or Uno Platform.
The desktop UI shall provide functionalities for local client configuration and monitoring, including tag configuration and namespace browsing.",User Interface & Experience (UI/UX),"For desktop applications, frameworks like Avalonia UI or Uno Platform will be considered for local client interaction.",,,,FALSE,medium,
1986,REQ-UIX-004,Functional,"The UI (both web and desktop, if applicable) shall provide functionality for users to configure OPC tags.
This includes support for drag-and-drop style interactions for tag configuration where appropriate and feasible.
The UI shall enable users to browse OPC server namespaces to discover available tags and data structures.",User Interface & Experience (UI/UX),"Includes features such as tag configuration (e.g., drag-and-drop style interactions where appropriate), namespace browsing...",,,,FALSE,high,
1987,REQ-UIX-005,Functional,"The UI shall feature customizable dashboards for real-time and historical data visualization.
Users shall be able to create, modify, and save dashboard layouts, selecting data points and visualization types.
Dashboards shall utilize specified charting libraries to display trends, gauges, and other visual elements.
The UI shall support visualization of aggregated and filtered historical data on these dashboards.",User Interface & Experience (UI/UX),"customizable dashboards for data visualization using charting libraries (e.g., Chart.js, Plotly.js, or .NET-based libraries like Syncfusion/Telerik UI components [Essential for dashboards and trend visualization]).",,,,FALSE,high,
1988,REQ-UIX-006,Functional,"The UI shall support localization into multiple languages, initially including English, German, Spanish, and Chinese.
The system shall provide a framework enabling straightforward addition of new languages.
Localization shall encompass UI text, number formats, and date/time formats, ensuring UTF-8 text encoding for all supported languages.
The default language and regional settings for the UI shall be configurable based on site or user preferences.",User Interface & Experience (UI/UX),"Target languages for localization will be specified based on market requirements (e.g., English, German, Spanish, Chinese), with a framework allowing for straightforward addition of new languages. If multi-language support is required, the UI and documentation must be localizable, supporting target languages (to be specified), different number formats, date/time formats, and UTF-8 text encoding. The default language and regional settings for the UI will be configurable based on site or user preferences, aligning with organizational policies for multilingual environments.",,,,FALSE,medium,
1989,REQ-UIX-007,Functional,"The UI shall allow users to view current values of OPC tags in real-time.
The UI shall enable authorized users to write new values to OPC tags.
The UI shall display clear, user-friendly status messages for both successful and failed read/write operations, including details for errors like communication timeouts, connection loss, or invalid tag addresses.",User Interface & Experience (UI/UX),"Allows users to browse server namespaces, read current tag values, and write updates. Error handling for failed read/write operations (e.g., communication timeouts, connection loss, invalid tag address) will be implemented, providing clear status codes and messages to the calling application or UI.",,,,FALSE,high,
1990,REQ-UIX-008,Functional,"The UI shall provide tools for querying and visualizing historical data from OPC HDA servers or the system's time-series database.
Users shall be able to specify time ranges, select tags, and apply data aggregation functions via the UI.
Trend visualization tools within the UI shall allow users to analyze historical data patterns.
The UI shall display results of HDA queries, with query response times for a 1-day range of 100 tags aimed to be less than 2 seconds for UI display.
Informative feedback shall be provided for HDA query errors (e.g., data not found, timeout).",User Interface & Experience (UI/UX),"Implements the OPC Historical Access specification, supporting queries over specific time ranges. Includes data aggregation, filtering, and trend visualization tools. Query response times for a 1-day range of 100 tags should be less than 2 seconds... Error handling for HDA queries... will provide informative feedback.",,,,FALSE,high,
1991,REQ-UIX-009,Functional,"The UI shall provide a dedicated interface for monitoring and managing OPC Alarms and Conditions.
Users shall be able to view alarm details including: timestamp of occurrence, source node, event type, severity, condition name, message, acknowledged state, and timestamp of acknowledgment/return-to-normal.
The UI shall allow authorized users to acknowledge alarms.
UI alerts shall be a configurable notification mechanism for new or critical alarms.",User Interface & Experience (UI/UX),"Provides a user interface for acknowledging alarms. Alarm records will include at least: timestamp of occurrence, source node, event type, severity, condition name, message, acknowledged state, and timestamp of acknowledgment/return-to-normal. The system will support configurable notification mechanisms for alarms, such as UI alerts...",,,,FALSE,high,
1992,REQ-UIX-010,NonFunctional,"The UI shall meet defined performance targets: dashboard load times shall be less than 3 seconds (P95).
UI interaction response times for common operations (e.g., opening dialogs, submitting forms, navigating views) shall be less than 200ms (P95).",User Interface & Experience (UI/UX),UI performance targets will include dashboard load times of less than 3 seconds (P95) and UI interaction response times of less than 200ms (P95) for common operations.,,,,FALSE,high,
1993,REQ-UIX-011,Functional,"The UI shall notify users of OPC server failover events.
The UI shall provide authorized operators with controls for manual initiation of failover to a backup OPC server.
The UI shall provide authorized operators with controls for manual failback to the primary OPC server when it is restored and appropriate.",User Interface & Experience (UI/UX),Users will be notified of failover events through the UI and configurable alert mechanisms. The system will provide operators with the capability for manual failover initiation and failback to the primary server when appropriate.,,,,FALSE,medium,
1994,REQ-UIX-012,Functional,"The UI (specifically the centralized management dashboard and potentially local client UIs) shall display Key Performance Indicators (KPIs) of the OPC client application's health.
Displayed KPIs shall include OPC server connection status, message queue lengths, CPU/memory utilization of client components, and data throughput.
The UI may provide views or links to integrated monitoring tools (e.g., Kibana, Grafana) for detailed log analysis and system metrics if such integration is implemented.",User Interface & Experience (UI/UX),"Key Performance Indicators (KPIs) for client health, such as connection status to OPC servers, message queue lengths, CPU/memory utilization, and data throughput, will be tracked. ... Logs will be aggregated and analyzed using tools like the ELK Stack (Elasticsearch, Logstash, Kibana), Splunk, or cloud-native solutions...",,,,FALSE,medium,
1995,REQ-UIX-013,Functional,"The UI shall display predictions and alerts generated by the AI-driven predictive maintenance models.
The UI shall provide a feedback mechanism allowing authorized users (e.g., maintenance planners, engineers) to validate or correct these maintenance predictions.
This user feedback shall be captured by the system for potential AI model refinement.",User Interface & Experience (UI/UX),"A feedback mechanism will allow users to validate or correct maintenance predictions, which can be used for future model refinement.",,,,FALSE,medium,
1996,REQ-UIX-014,Functional,"The UI shall present detected data anomalies to authorized users (e.g., operators, process engineers).
The UI shall provide an interface for users to review details of these detected anomalies.
Users shall be able to label anomalies (e.g., true positive, false positive, specific cause) via the UI.
The UI shall allow authorized users to manage the lifecycle of detected anomalies (e.g., acknowledge, escalate, close).",User Interface & Experience (UI/UX),"A user interface will be provided for reviewing, labeling, and managing detected anomalies, facilitating model retraining and performance improvement.",,,,FALSE,medium,
1997,REQ-UIX-015,Functional,"The UI shall provide an input field for users to type natural language queries for data retrieval.
The UI shall support voice input as an alternative method for submitting Natural Language Queries (NLQ), using integrated voice recognition services.
For ambiguous or unrecognized NLQ queries, the UI shall provide a fallback mechanism, such as offering alternative interpretations, asking for clarification, or guiding the user to manual browsing/querying tools.",User Interface & Experience (UI/UX),"Integrates NLP ... to process queries like Show current temperature in Tank 1. Supports voice input. The system will include a fallback mechanism for ambiguous or unrecognized queries, such as offering alternative interpretations, asking for clarification, or guiding the user to manual browsing/querying tools.",,,,FALSE,low,
1998,REQ-UIX-016,Functional,"The UI shall provide a user-configurable mapping or aliasing system.
This system shall allow users to define semantic names, contexts, or aliases for their OPC data points.
This configuration is intended to improve the accuracy and relevance of the Natural Language Querying feature for their specific operational environment.",User Interface & Experience (UI/UX),"A user-configurable mapping or aliasing system will be provided, allowing users to define semantic names, contexts, or tags for their OPC data points. This metadata enables the NLP engine to correctly interpret queries related to their specific plant, equipment, or processes.",,,,FALSE,low,
1999,REQ-UIX-017,Functional,"The UI shall provide options for users to customize report templates, including selecting data sources, KPIs, chart types, and branding elements.
The UI shall allow users to schedule automated report generation or trigger it on-demand.
Generated reports (e.g., in PDF, Excel, HTML formats) shall be downloadable directly from the web UI.",User Interface & Experience (UI/UX),"Users will have options to customize report templates, including selecting data sources (with clear definition of data models for report inputs), KPIs, chart types, and branding elements. Supports scheduled or event-triggered reporting in various formats (e.g., PDF, Excel, HTML [Important for user consumption]). Reports can be distributed via multiple channels, including email, download from the web UI, or saved to configured network locations.",,,,FALSE,medium,
2000,REQ-UIX-018,Functional,"The system shall support an Augmented Reality (AR) interface for visualizing data on physical equipment via compatible AR devices.
AR visualizations shall include options for displaying data as numerical readouts, historical trend charts, and status indicators (e.g., color-coded).
The AR interface shall allow overlaying relevant documentation or work instructions onto the view of the physical equipment.
Interaction methods in AR shall support gaze, standard mobile touch gestures (for tablet/phone AR), and potentially voice commands.",User Interface & Experience (UI/UX),"Integrates with AR devices (e.g., HoloLens, AR-enabled tablets/smartphones) to overlay real-time data on machinery... AR visualizations will include options for displaying data as numerical readouts, historical trend charts, status indicators... Interaction methods in AR will support gaze, standard mobile touch gestures... and potentially voice commands... overlaying relevant documentation or work instructions.",,,,FALSE,low,
2001,REQ-UIX-019,Functional,"The UI shall provide a configuration interface allowing authorized users to select specific OPC tags, events, or data change thresholds that trigger logging to the blockchain.
The UI shall provide a secure and user-friendly process for retrieving blockchain records.
The UI shall facilitate the verification of data integrity by enabling comparison of off-chain data with on-chain hashes or records.",User Interface & Experience (UI/UX),"A configuration interface will be provided, allowing users to select specific OPC tags, events, or data change thresholds that should be considered 'critical'. ... A secure and user-friendly process will be provided for retrieving and verifying data integrity using the blockchain records...",,,,FALSE,low,
2002,REQ-UIX-020,Functional,"The UI shall provide clear feedback for voice commands used for controlling the client or querying data, such as visual confirmation on the UI or synthesized audio responses.
If custom voice command definition is supported by the underlying voice recognition engine, the UI may allow users to define custom voice commands or aliases for frequently used operations or queries.",User Interface & Experience (UI/UX),"The system will provide clear feedback for voice commands, such as visual confirmation on the UI or synthesized audio responses. Users may have the ability to define custom voice commands or aliases for frequently used operations or queries...",,,,FALSE,low,
2003,REQ-UIX-021,Functional,"The UI shall enable users to configure the connection and data exchange with digital twin platforms.
This includes UI elements for configuring data mapping and transformation rules between OPC data models and Digital Twin models.
The UI shall allow users to set the data synchronization frequency between the OPC client and the digital twin.
The UI shall display data being exchanged with the digital twin and potentially allow initiation of commands to/from the twin, subject to system capabilities.",User Interface & Experience (UI/UX),Connects to digital twins for simulation and testing... Interaction will adhere to standards or protocols... The scope of interaction will include bi-directional data flow... Data mapping and transformation rules between OPC data models and Digital Twin models will be configurable... Data synchronization frequency... will be configurable.,,,,FALSE,low,
2004,REQ-UIX-022,Functional,"The system's server-side application shall serve a web-based dashboard for centralized management.
This dashboard shall enable administrators to monitor the status and health of multiple OPC client instances across different sites.
It shall provide comprehensive remote configuration capabilities for all managed client instances, including headless ones.
The dashboard shall support bulk operations for efficiently configuring multiple client instances simultaneously (e.g., deploying standard configurations, software updates).
Key Performance Indicators (KPIs) summarizing the overall health, connectivity, and performance of all managed client instances shall be prominently displayed on this dashboard.",User Interface & Experience (UI/UX),"Provides a web-based dashboard, served by the server-side application component of the hybrid architecture, for monitoring and comprehensively configuring clients across sites. This includes the ability to fully manage all client instances, including those deployed headlessly. The centralized dashboard will support bulk operations for configuring multiple client instances simultaneously... Key Performance Indicators (KPIs) summarizing the overall health, connectivity, and performance of all managed client instances will be prominently displayed on the centralized dashboard...",,,,FALSE,high,
2005,REQ-UIX-023,Functional,"The UI (primarily the web-based interface) shall support customization to align with organizational branding guidelines.
This includes allowing authorized administrators to configure corporate logos and color schemes.
The UI shall support the configuration of default dashboard layouts that can be standardized across users or sites.
These UI customizations must be manageable through an administrative interface.",User Interface & Experience (UI/UX),"Any UI customizations, such as corporate branding (logos, color schemes) or default dashboard layouts, must adhere to organizational branding guidelines and be approved by relevant stakeholders.",,,,FALSE,medium,
2006,REQ-UIX-024,Functional,"The system shall provide access to comprehensive user documentation, including User Manuals, Administrator Guides, and Installation Guides.
This documentation shall be accessible, potentially through links within the UI, a dedicated help menu, or a specified hosted documentation portal.
If e-learning modules or video tutorials are provided, the UI may offer access points or links to these training materials.",User Interface & Experience (UI/UX),"Includes documentation (User Manual, Administrator Guide, Installation Guide, API Documentation, Troubleshooting Guide, Release Notes) hosted on a platform like ReadtheDocs, Confluence, or a custom portal... Training materials will be available in various formats, including written documentation, video tutorials, and potentially interactive e-learning modules.",,,,FALSE,medium,
2007,REQ-DLP-001,Functional,"The system shall store historical process data in a time-series database (e.g., InfluxDB, TimescaleDB) optimized for efficient querying and long-term storage. The historical data model shall include, at a minimum, timestamp, tag identifier, value, quality, and any relevant metadata.",Data Lifecycle & Performance Management,"Historical data and alarm/event logs will be stored in a suitable time-series database (e.g., InfluxDB, TimescaleDB) for efficient querying and long-term storage. The data model for historical data storage will specify fields such as timestamp, tag identifier, value, quality, and any relevant metadata.",,,,FALSE,high,
2008,REQ-DLP-002,Functional,"The system shall ingest historical data into the time-series database using optimized batching mechanisms or streaming connectors. It shall support configurable data validation rules (e.g., timestamp sanity checks, value range checks) applied prior to data ingestion.",Data Lifecycle & Performance Management,"Data ingestion into the time-series database will be handled via optimized batching mechanisms or streaming connectors, with configurable data validation rules (e.g., timestamp sanity checks, value range checks) prior to ingestion.",,,,FALSE,high,
2009,REQ-DLP-003,NonFunctional,"The system shall provide historical data query response times of less than 2 seconds for a 1-day range of 100 tags (P95). Queries shall utilize native database query languages. The system shall implement error handling for HDA queries, providing informative feedback for scenarios like 'data not found', 'query timeout', or 'invalid parameters'.",Data Lifecycle & Performance Management,"Query response times for a 1-day range of 100 tags should be less than 2 seconds, utilizing native query languages like Flux for InfluxDB or SQL for TimescaleDB. Error handling for HDA queries (e.g., data not found for the specified range, query timeout, invalid aggregation parameters) will provide informative feedback.",,,,FALSE,high,
2010,REQ-DLP-004,Functional,"The system shall provide a documented process and supporting tools/scripts for migrating historical data from common legacy systems (e.g., proprietary historians, SQL databases) into its time-series database. This process must include data extraction, transformation (e.g., timestamp normalization, tag mapping, unit conversion), loading, and validation (e.g., record counts, spot checks, aggregate comparisons).",Data Lifecycle & Performance Management,"For customers with existing historical data in other systems (e.g., proprietary historians, SQL databases), a comprehensive data migration plan will be developed. This includes defining procedures for data extraction, transformation (e.g., timestamp normalization, tag name mapping, unit conversion), loading into the new time-series database, and rigorous validation of migrated data against source data (e.g., record counts, spot checks, aggregate comparisons). Tools and scripts to support this migration will be considered.",,,,FALSE,medium,
2011,REQ-DLP-005,Functional,"The system shall store alarm and event data in a time-series database for robust logging and analysis. The alarm data model shall include, at a minimum: timestamp of occurrence, source node, event type, severity, condition name, message, acknowledged state, and timestamp of acknowledgment/return-to-normal.",Data Lifecycle & Performance Management,"Alarm records will include at least: timestamp of occurrence, source node, event type, severity, condition name, message, acknowledged state, and timestamp of acknowledgment/return-to-normal. This defines the core data model for alarms. Alarm and event data will be stored in a time-series database (e.g., InfluxDB, TimescaleDB) for robust logging and analysis.",,,,FALSE,high,
2012,REQ-DLP-006,Functional,"The system shall implement configurable data validation rules for incoming alarm and event data prior to storage, ensuring, for example, that all required fields as per the defined data model are present.",Data Lifecycle & Performance Management,"Data validation rules for incoming alarm and event data (e.g., ensuring required fields are present) will be implemented.",,,,FALSE,high,
2013,REQ-DLP-007,Functional,The system shall provide a documented procedure for migrating existing alarm and event logs from legacy systems into the new time-series database. This procedure must include schema mapping and data validation to ensure continuity of historical alarm analysis.,Data Lifecycle & Performance Management,"Procedures for migrating existing alarm and event logs from legacy systems into the new time-series database will be defined, including schema mapping and validation, to ensure continuity of historical alarm analysis.",,,,FALSE,medium,
2014,REQ-DLP-008,Security,"The system shall store user configurations and other designated sensitive data in a relational database (e.g., PostgreSQL, SQL Server) with encryption at rest (e.g., AES-256). Sensitive alarm/event logs and historical process values stored in specialized databases (e.g., time-series databases) shall also be protected with equivalent security measures, including encryption at rest.",Data Lifecycle & Performance Management,"User configurations and other specifically designated sensitive data will be stored using a relational database (e.g., PostgreSQL, SQL Server) with appropriate security measures including encryption at rest. Other categories of data that may be sensitive, such as alarm/event logs or historical process values, will be stored in their respective specialized databases (e.g., time-series databases for historical data and alarm/event logs) with security measures equivalent to those applied to the relational database, ensuring consistent and robust security across all data stores handling sensitive information.",,,,FALSE,high,
2015,REQ-DLP-009,Functional,"The system shall provide capabilities for data masking or anonymization of sensitive data for use in non-production environments or specific use cases, as configured by an administrator.",Data Lifecycle & Performance Management,"Where applicable for non-production environments or specific use cases, data masking or anonymization techniques will be available for sensitive data.",,,,FALSE,medium,
2016,REQ-DLP-010,Performance,"The system shall support grouping of OPC items to enable efficient bulk read and write operations, thereby optimizing communication with OPC servers.",Data Lifecycle & Performance Management,Groups OPC items for efficient read/write operations.,,,,FALSE,high,
2017,REQ-DLP-011,NonFunctional,"The system architecture shall be designed to support: at least 50 concurrent OPC server connections per client instance, up to 100,000 monitored items (tags) per client instance, and at least 100 concurrent users accessing centralized dashboards, while maintaining defined performance levels.",Data Lifecycle & Performance Management,"The system should be designed to support a specified number of concurrent OPC server connections (e.g., X connections, with a target of X=50), a total number of monitored items per client instance (e.g., Y items, with a target of up to 100,000 tags), and a specified number of concurrent users for centralized dashboards (e.g., Z users, with a target of Z=100).",,,,FALSE,high,
2018,REQ-DLP-012,NonFunctional,The system's user interface shall achieve dashboard load times of less than 3 seconds (P95) and UI interaction response times of less than 200ms (P95) for common operations under typical load conditions.,Data Lifecycle & Performance Management,UI performance targets will include dashboard load times of less than 3 seconds (P95) and UI interaction response times of less than 200ms (P95) for common operations.,,,,FALSE,high,
2019,REQ-DLP-013,Performance,"The system shall implement multi-level caching strategies, including in-memory caching for frequently accessed data (client/server), distributed caching (e.g., Redis) for shared data, and browser/CDN caching for web UI assets, to optimize performance and reduce latency.",Data Lifecycle & Performance Management,"Caching strategies (e.g., in-memory caching for frequently accessed data on the client/server, distributed caching like Redis for shared data, and browser/CDN caching for web assets) will be implemented.",,,,FALSE,high,
2020,REQ-DLP-014,Performance,"The system shall utilize data compression techniques (e.g., Gzip for HTTP, OPC UA binary encoding optimizations) for data transfer between components and with external systems where it reduces bandwidth consumption without significantly impacting processing latency. The use of compression shall be configurable or intelligently applied.",Data Lifecycle & Performance Management,"Data compression techniques (e.g., Gzip for HTTP, or OPC UA binary encoding optimizations) will be utilized for data transfer where beneficial and appropriate to reduce bandwidth consumption without significantly impacting latency.",,,,FALSE,medium,
2021,REQ-DLP-015,NonFunctional,"The system design shall account for expected data growth rates for historical data, alarm/event logs, and AI-generated data to ensure sustained performance. Documentation shall provide storage sizing guidelines based on configurable parameters (e.g., number of tags, data retention period, logging frequency).",Data Lifecycle & Performance Management,"Expected data growth rates for AI and historical data will be considered in system design to ensure sustained performance, and storage sizing guidelines will be provided.",,,,FALSE,medium,
2022,REQ-DLP-016,NonFunctional,"The system shall undergo performance and load testing using industry-standard tools (e.g., k6, JMeter, Azure Load Testing) against defined test scenarios and quality criteria (pass/fail) to verify that all specified performance targets (e.g., response times, throughput, scalability) are met.",Data Lifecycle & Performance Management,"Load testing using tools like k6, JMeter, or Azure Load Testing will be conducted to verify performance targets, with defined test scenarios and quality criteria for pass/fail.",,,,FALSE,high,
2023,REQ-DLP-017,Functional,"The system shall implement configurable data retention policies for historical data, alarm logs, AI-generated data (including prediction scores, model parameters, feature vectors), and audit trails. The system shall provide suggested default retention periods for each data type, which must be user-configurable.",Data Lifecycle & Performance Management,"Configurable data retention policies will be implemented for various data types, including historical data, alarm logs, AI-generated data (e.g., prediction scores, model parameters, feature vectors), and audit trails. Default retention periods will be suggested for different data types, while remaining fully configurable by the user.",,,,FALSE,high,
2024,REQ-DLP-018,Functional,"The system's data retention policies shall support automated archiving of data (e.g., historical, alarm logs) to configurable cost-effective storage locations (e.g., AWS S3 Glacier, Azure Blob Archive Storage). The policies shall also support automated secure purging of data based on configured time duration or storage capacity limits, in compliance with operational and regulatory needs.",Data Lifecycle & Performance Management,"These policies will include mechanisms for automated archiving to cost-effective storage (e.g., AWS S3 Glacier, Azure Blob Archive Storage) and secure purging based on time duration or storage capacity limits, ensuring compliance with operational and regulatory requirements.",,,,FALSE,high,
2025,REQ-DLP-019,Functional,"The system shall record all significant data management actions in audit logs. This includes, but is not limited to, changes to data retention policies, data archiving operations, and data purging operations, with details such as timestamp, user (if applicable), and action performed.",Data Lifecycle & Performance Management,"Audit logs will record all significant data management actions, including policy changes, data archiving, and purging operations.",,,,FALSE,high,
2026,REQ-DLP-020,NonFunctional,"The system shall have a documented backup and recovery strategy for all its persistent data (e.g., configurations, local caches if persistent, AI model metadata). This strategy must specify backup frequency, storage locations (on-premise/cloud), Recovery Time Objective (RTO), Recovery Point Objective (RPO), and recommended tools (e.g., database-native, cloud provider services, third-party solutions).",Data Lifecycle & Performance Management,"Backup and recovery strategies will be specified for all persistent data generated or managed by the client system itself (e.g., configurations, local data caches, AI model metadata), including backup frequency, storage locations (on-premise or cloud storage), and defined RTO/RPO for this internal data, utilizing database-native tools, cloud provider backup services (e.g., Azure Backup, AWS Backup), or third-party backup solutions.",,,,FALSE,high,
2027,REQ-DLP-021,Functional,The system's documented recovery procedures shall include steps for post-recovery data validation and integrity checks to ensure data consistency after a restoration event.,Data Lifecycle & Performance Management,Post-recovery data validation and integrity checks will be part of the defined recovery procedures to ensure data consistency.,,,,FALSE,high,
2028,REQ-DLP-022,Functional,The system shall provide documented data migration strategies for its configurations and any locally stored persistent data to support scenarios like version upgrades or client instance migrations. These strategies must include source-to-target mapping and validation procedures.,Data Lifecycle & Performance Management,"Data migration strategies for system configurations and locally stored data (e.g., during version upgrades or instance migration) will be documented, including source-to-target mapping and validation procedures.",,,,FALSE,medium,
2029,REQ-DLP-023,Functional,The system shall provide a plan or methodology for integrating or migrating existing data archives from legacy systems into its data management framework. This includes assessing archive format compatibility and ensuring continued data accessibility post-migration/integration.,Data Lifecycle & Performance Management,"If migrating from a system with existing data archives, a plan for integrating or migrating these archives into the new system's data management framework will be developed. This includes assessing compatibility of archive formats and ensuring continued accessibility.",,,,FALSE,low,
2030,REQ-DLP-024,Functional,"The system shall support storage of AI-related unstructured data and model artifacts (e.g., pre-trained models in ONNX format, model parameters, feature vectors) using suitable storage solutions such as NoSQL databases (e.g., MongoDB) or blob storage. Defined schemas or structures for this data shall be documented.",Data Lifecycle & Performance Management,"AI-related unstructured data or model artifacts may utilize NoSQL databases (e.g., MongoDB) or blob storage, with defined schemas or structures.",,,,FALSE,medium,
2031,REQ-DLP-025,Functional,"For critical data designated for blockchain logging, the system shall store a hash of the data payload, timestamp, and source/destination identifiers on the blockchain. The actual voluminous data shall be stored off-chain. The data model for on-chain entries and associated off-chain data shall be clearly defined and documented.",Data Lifecycle & Performance Management,"The data designated for blockchain logging (e.g., a hash of the data payload, timestamp, and source/destination identifiers, with actual data stored off-chain if voluminous) will then be asynchronously queued and committed to the blockchain... The data model for blockchain entries and associated off-chain data will be defined.",,,,FALSE,medium,
2032,REQ-DLP-026,Functional,"The system shall define and implement retention and archival strategies for off-chain data that is linked from blockchain entries, ensuring its availability for verification purposes throughout the lifecycle of the blockchain record.",Data Lifecycle & Performance Management,Retention and archival strategies for off-chain data linked from the blockchain will be defined.,,,,FALSE,medium,
2033,REQ-DLP-027,NonFunctional,"The system shall allow tuning of its configuration parameters (e.g., polling rates, subscription parameters, caching settings) to meet defined performance SLAs for data access and UI responsiveness, while operating within specified network bandwidth and server resource limitations as per organizational IT policies.",Data Lifecycle & Performance Management,"Business Rule: The system configuration must be tuned (e.g., polling rates, subscription parameters, caching settings) to meet the defined performance SLAs for data access and UI responsiveness, while respecting network bandwidth and server resource limitations as per organizational IT policies.",,,,FALSE,high,
2034,REQ-DLP-028,NonFunctional,"The system, in conjunction with monitoring tools, shall support the identification of performance degradation below agreed thresholds. Such events must trigger a documented investigation and corrective action planning process within the customer organization.",Data Lifecycle & Performance Management,Business Rule: Any performance degradation below agreed thresholds must trigger an investigation and corrective action plan.,,,,FALSE,medium,
2035,REQ-DLP-029,Functional,"The system's configurable data retention policies shall enable customers to set retention periods for all managed data types (historical, alarms, AI, audit trails) in a manner that complies with applicable legal statutes and industry-specific regulations relevant to the customer.",Data Lifecycle & Performance Management,"Business Rule: Data retention periods for all data types must comply with applicable legal statutes (e.g., Sarbanes-Oxley, HIPAA) and industry-specific regulations (e.g., NERC CIP for energy, FDA regulations for pharma).",,,,FALSE,high,
2036,REQ-DLP-030,Functional,"All data purging actions, whether automated by policy or manually initiated, shall be recorded in an audit log. Manual purging operations outside of automated policy shall require a mechanism for recording approval or authorization, if supported by the system's workflow, or be subject to external organizational approval processes.",Data Lifecycle & Performance Management,"Business Rule: Data purging must be an auditable process, with clear approvals required for manual purges outside of automated policy.",,,,FALSE,high,
2037,REQ-DLP-031,NonFunctional,"The system documentation shall recommend and support periodic review and testing (e.g., annually) of data backup and recovery procedures by the customer to ensure their continued effectiveness and compliance with defined RTO/RPO targets for system-managed data.",Data Lifecycle & Performance Management,"Business Rule: Periodic review and testing of data backup and recovery procedures (e.g., annually) are mandatory to ensure their effectiveness and compliance with RTO/RPO targets for system-managed data.",,,,FALSE,medium,
2038,REQ-DLP-032,NonFunctional,The system documentation shall advise the customer organization to define clear data ownership and stewardship roles and responsibilities for all data types managed by the OPC client system.,Data Lifecycle & Performance Management,Business Rule: Clear data ownership and stewardship roles and responsibilities within the customer organization must be defined for all data managed by the system.,,,,FALSE,low,
2039,REQ-6-001,Functional,"The system shall provide a web-based dashboard, served by the server-side application, enabling centralized monitoring and comprehensive configuration of all OPC client instances, including headless ones, across multiple sites.",System Operations & Centralized Management,"Provides a web-based dashboard, served by the server-side application component of the hybrid architecture, for monitoring and comprehensively configuring clients across sites. This includes the ability to fully manage all client instances, including those deployed headlessly.",,,,FALSE,high,
2040,REQ-6-002,Functional,"The centralized management dashboard shall support bulk operations for simultaneous configuration (e.g., deploying standard configurations) and software updates of multiple selected client instances. It shall prominently display aggregated Key Performance Indicators (KPIs) for overall health, connectivity, and performance of all managed clients, based on defined and documented data sources.",System Operations & Centralized Management,"The centralized dashboard will support bulk operations for configuring multiple client instances simultaneously (e.g., deploying standard configurations, updating software). Key Performance Indicators (KPIs) summarizing the overall health, connectivity, and performance of all managed client instances will be prominently displayed on the centralized dashboard, with defined data sources for these KPIs.",,,,FALSE,high,
2041,REQ-6-003,NonFunctional,"All administrative functions available through the centralized management dashboard shall be clearly documented. Access to the dashboard and its functions shall be strictly controlled via Role-Based Access Control (RBAC). All significant administrative actions performed via the dashboard (e.g., configuration changes, bulk operations, user management) shall be logged in an audit trail.",System Operations & Centralized Management,"Administrative functions available through this interface will be clearly documented. Access to the centralized management dashboard must be strictly controlled and audited, given its wide-ranging control capabilities. Administrative responsibilities and procedures for using the centralized management dashboard, including who can perform bulk operations or deploy configurations, must be clearly defined and documented.",,,,FALSE,high,
2042,REQ-6-004,Functional,"The system shall implement comprehensive structured logging for all its components, utilizing frameworks like Serilog or NLog for .NET applications. Logs must include timestamp, severity level, source component, and relevant contextual information. The system shall track and make accessible specific Key Performance Indicators (KPIs) for client and server health, including: OPC server connection status and round-trip time, subscription queue lengths, message processing rates, CPU/memory/disk utilization of client and server components, and API request latency and error rates.",System Operations & Centralized Management,"Implements comprehensive logging capabilities, including structured logs using a framework like Serilog or NLog for .NET applications. Log data will include timestamps, severity levels, source component, and relevant contextual information. Key Performance Indicators (KPIs) for client health... will be tracked. Specific KPIs to be monitored will include (but not be limited to): OPC server connection status and round-trip time, subscription queue lengths, message processing rates, CPU/memory/disk utilization of client and server components, API request latency and error rates.",,,,FALSE,high,
2043,REQ-6-005,Functional,"The system shall allow configuration of alerting thresholds for the tracked Key Performance Indicators (KPIs). It shall support configurable application log rotation and retention policies to manage disk space and ensure diagnostic data availability. The system must provide mechanisms to integrate with external log aggregation/analysis tools (e.g., ELK Stack, Splunk, Azure Monitor Logs, AWS CloudWatch Logs) and standard monitoring/observability platforms (e.g., Prometheus, Grafana, Azure Monitor, AWS CloudWatch) for real-time monitoring and alerting.",System Operations & Centralized Management,"Alerting thresholds for these KPIs will be configurable. Logs will be aggregated and analyzed using tools like the ELK Stack... Application log rotation and retention policies will be configurable... The system will support integration with standard monitoring and observability platforms (e.g., Prometheus, Grafana...)",,,,FALSE,high,
2044,REQ-6-006,NonFunctional,"The system shall implement distributed tracing, using OpenTelemetry standards, for requests that span multiple services within its hybrid architecture. The server-side application components shall be designed and deployed to achieve a target availability of 99.9% uptime, excluding scheduled maintenance periods.",System Operations & Centralized Management,"Distributed tracing (e.g., using OpenTelemetry) will be implemented for requests spanning multiple services within the hybrid architecture. The server-side application components will have a defined target availability (e.g., 99.9% uptime, excluding scheduled maintenance).",,,,FALSE,high,
2045,REQ-6-007,NonFunctional,"The system shall support the delivery of regular software updates, including new features, security patches, and compatibility improvements, via a secure mechanism (e.g., signed packages, secure download portal). A documented rollback strategy must be provided to allow reversion to a previous stable version in case of critical issues with an update. Each software update must be accompanied by comprehensive release notes detailing new features, improvements, bug fixes, and any breaking changes.",System Operations & Centralized Management,"Delivers new features, security patches, and compatibility improvements regularly... Updates will be delivered via a secure mechanism... A documented rollback strategy will be in place... Comprehensive release notes detailing new features, improvements, bug fixes, and any breaking changes will accompany each update.",,,,FALSE,high,
2046,REQ-6-008,Technical,"Software updates provided for the system shall be developed using a version control system (e.g., Git) and processed through a Continuous Integration/Continuous Deployment (CI/CD) pipeline that automates building and testing. The quality assurance process for updates must include comprehensive testing encompassing unit, integration, end-to-end, performance (against defined criteria), and security (SAST, DAST, penetration) testing prior to release.",System Operations & Centralized Management,"Development will use a version control system (e.g., Git)... A CI/CD pipeline... will automate building, testing, and deploying updates. The testing strategy will encompass unit tests..., integration tests..., end-to-end tests..., performance tests..., and security testing (SAST, DAST, penetration testing).",,,,FALSE,high,
2047,REQ-6-009,NonFunctional,"The system documentation shall provide clear guidance and recommendations for customer organizations regarding patching schedules, particularly for critical security vulnerabilities. It shall also outline best practices for defining internal responsibilities and procedures for testing updates in a staging environment, approving them for production, and applying them during scheduled maintenance windows, in alignment with their internal change management and IT security policies.",System Operations & Centralized Management,"The customer organization must adhere to vendor-recommended patching schedules... Organizational responsibilities for testing updates in a staging environment, approving them for production, and applying them during scheduled maintenance windows must be clearly defined.",,,,FALSE,medium,
2048,REQ-7-001,Functional,"The system shall integrate pre-trained predictive maintenance models, supporting ONNX format for interoperability, to analyze historical data and forecast equipment maintenance needs. The system shall support running these models on edge devices for low-latency predictions.",Advanced Analytics & Artificial Intelligence (AI/ML),Integrates pre-trained models (potentially in ONNX format for interoperability) to analyze historical data and forecast maintenance needs. Can run on edge devices for low-latency predictions.,,,,FALSE,high,
2049,REQ-7-002,Functional,"The system shall enforce and utilize clearly documented input data requirements for predictive maintenance models, including specific sensor data, operational parameters, data formats, expected data quality levels, and mechanisms for handling missing or anomalous input data.",Advanced Analytics & Artificial Intelligence (AI/ML),"Input data requirements for pre-trained models (e.g., specific sensor data, operational parameters, data formats, expected data quality levels including handling of missing or anomalous input data) will be clearly documented.",,,,FALSE,high,
2050,REQ-7-003,Technical,"The system shall support the execution of predictive maintenance models developed using AI/ML frameworks including TensorFlow, PyTorch, scikit-learn, and ML.NET, primarily through ONNX or other specified interoperable formats.",Advanced Analytics & Artificial Intelligence (AI/ML),"AI/ML frameworks such as TensorFlow, PyTorch, scikit-learn, or ML.NET will be utilized for model development and execution.",,,,FALSE,medium,
2051,REQ-7-004,Functional,"The system shall provide AI model management capabilities for predictive maintenance, including deploying and versioning models, monitoring model performance for drift (e.g., accuracy degradation), and supporting a retraining strategy. Integration with MLOps platforms (e.g., MLflow, Kubeflow, Azure ML, AWS SageMaker) shall be supported.",Advanced Analytics & Artificial Intelligence (AI/ML),"A comprehensive AI model management strategy will be defined, including processes for deploying and versioning pre-trained models, monitoring their performance over time for drift, and outlining a retraining strategy, potentially using MLOps platforms/tools (e.g., MLflow, Kubeflow, Azure Machine Learning, AWS SageMaker).",,,,FALSE,high,
2052,REQ-7-005,Functional,"The system shall provide model explainability features (e.g., SHAP, LIME) for predictive maintenance predictions where feasible. It shall include a user feedback mechanism to validate or correct predictions, with feedback logged for model refinement. The system shall allow authorized users to upload pre-trained custom models or fine-tune existing models with their operational data.",Advanced Analytics & Artificial Intelligence (AI/ML),"The system will aim to provide model explainability features (e.g., using techniques like SHAP or LIME where feasible) to help users understand the basis of predictions. A feedback mechanism will allow users to validate or correct maintenance predictions, which can be used for future model refinement. The system may allow users to upload or train custom models, or fine-tune existing ones with their specific operational data.",,,,FALSE,medium,
2053,REQ-7-006,Technical,"The system shall store AI-related unstructured data and model artifacts (e.g., model parameters, feature vectors, training datasets metadata) using NoSQL databases (e.g., MongoDB) or blob storage, with defined schemas or structures for organization, versioning, and retrieval.",Advanced Analytics & Artificial Intelligence (AI/ML),"AI-related unstructured data or model artifacts may utilize NoSQL databases (e.g., MongoDB) or blob storage, with defined schemas or structures.",,,,FALSE,medium,
2054,REQ-7-007,NonFunctional,"The system's predictive maintenance features, including model development, training, fine-tuning, and deployment, shall adhere to documented ethical AI principles (fairness, transparency, accountability) and comply with applicable data privacy regulations (e.g., GDPR, CCPA) for all data used. Data privacy for customer-specific data shall be ensured throughout the model lifecycle.",Advanced Analytics & Artificial Intelligence (AI/ML),"Data privacy considerations for data used in model training or fine-tuning, especially if customer-specific data is involved, will be addressed. Ethical AI principles, including fairness, transparency, and accountability, must guide the development and deployment of predictive maintenance models. All data used for training must comply with data privacy regulations.",,,,FALSE,high,
2055,REQ-7-008,Functional,"The system shall employ AI models (statistical or deep learning) to detect and flag anomalies in real-time operational data. It shall support detection of point anomalies, contextual anomalies, and collective anomalies. The system shall allow configuration of detection thresholds and generate alerts for detected anomalies.",Advanced Analytics & Artificial Intelligence (AI/ML),"Detects unusual patterns in real-time data using AI. Employs statistical or deep learning models to flag anomalies. The system will be designed to detect various types of anomalies, including point, contextual, and collective anomalies. Configurable thresholds and alerts.",,,,FALSE,high,
2056,REQ-7-009,Functional,"The system shall enforce and utilize clearly documented input data requirements for anomaly detection models, including expected data quality levels, data sources, and necessary preprocessing steps.",Advanced Analytics & Artificial Intelligence (AI/ML),"Input data requirements, including expected data quality and preprocessing steps for anomaly detection models, will be documented.",,,,FALSE,high,
2057,REQ-7-010,Functional,"The system shall provide AI model management for anomaly detection, consistent with REQ-7-004, including model deployment, versioning, performance monitoring (e.g., false positive/negative rates), and retraining strategies. This includes support for user customization of anomaly detection models and adherence to data privacy for training data.",Advanced Analytics & Artificial Intelligence (AI/ML),"The AI model management strategy, AI/ML frameworks, and MLOps considerations (as detailed in AI-Driven Predictive Maintenance), including data privacy for training data, will also apply here, covering deployment, versioning, performance monitoring, retraining, and potential user customization of anomaly detection models.",,,,FALSE,high,
2058,REQ-7-011,Functional,"The system shall provide a user interface for authorized users to review details of detected anomalies, label them (e.g., true positive, false positive, specific anomaly type), and manage their lifecycle. This feedback shall be logged and made available for model retraining and performance improvement.",Advanced Analytics & Artificial Intelligence (AI/ML),"A user interface will be provided for reviewing, labeling, and managing detected anomalies, facilitating model retraining and performance improvement.",,,,FALSE,high,
2059,REQ-7-012,Functional,"The system shall support configurable workflows for reviewing, investigating, and responding to detected anomalies, including mechanisms for escalation of critical anomalies. The system must provide tools and metrics to facilitate regular review of anomaly detection model performance (e.g., false positive/negative rates, precision, recall) and support model retraining or adjustment using user feedback.",Advanced Analytics & Artificial Intelligence (AI/ML),"Business Rule: A defined workflow for reviewing, investigating, and responding to detected anomalies must be established. Business Rule: The performance of anomaly detection models must be regularly reviewed, and models retrained or adjusted as necessary. User feedback is critical.",,,,FALSE,high,
2060,REQ-7-013,Functional,"The system shall enable users to query OPC data using natural language text input via the user interface. The system shall also support voice input for submitting natural language queries, if the Voice Control feature is enabled.",Advanced Analytics & Artificial Intelligence (AI/ML),Enables data queries using natural language. Supports voice input.,,,,FALSE,medium,
2061,REQ-7-014,Functional,"The system shall integrate Natural Language Processing (NLP) capabilities, supporting specified services (e.g., Google Cloud NL, Azure Cognitive Services, or on-premise spaCy), for intent recognition and entity extraction from user queries. The system shall support a documented list of languages for NLQ, starting with English, with an architecture allowing for future language expansion.",Advanced Analytics & Artificial Intelligence (AI/ML),"Integrates NLP (e.g., Google Cloud Natural Language, Azure Cognitive Service for Language, or open-source libraries like spaCy if on-premise solutions are needed) to process queries. This involves intent recognition and entity extraction capabilities. Supported languages for Natural Language Querying will be specified.",,,,FALSE,high,
2062,REQ-7-015,Functional,"The system shall provide a user-configurable mapping or aliasing system allowing authorized users to define semantic names, contexts, or tags for OPC data points (e.g., mapping 'TT-101' to 'Reactor 1 Temperature'). This metadata shall be utilized by the NLP engine to improve the interpretation accuracy of queries specific to the user's operational environment.",Advanced Analytics & Artificial Intelligence (AI/ML),"A user-configurable mapping or aliasing system will be provided, allowing users to define semantic names, contexts, or tags for their OPC data points. This metadata enables the NLP engine to correctly interpret queries related to their specific plant, equipment, or processes.",,,,FALSE,high,
2063,REQ-7-016,NonFunctional,"The system shall implement robust error handling for external NLP service integrations, including configurable retries and circuit breaker patterns. For ambiguous or unrecognized natural language queries, the system shall provide fallback mechanisms, such as offering alternative interpretations, asking for clarification, or guiding the user to manual browsing/querying tools.",Advanced Analytics & Artificial Intelligence (AI/ML),"Robust error handling, retry mechanisms, circuit breaker patterns, and fallback strategies will be implemented for the integration with external NLP services. The system will include a fallback mechanism for ambiguous or unrecognized queries.",,,,FALSE,medium,
2064,REQ-7-017,NonFunctional,"The system shall ensure data privacy for logged natural language queries and any associated voice input data, particularly if processed by third-party NLP services. This includes compliance with relevant data privacy regulations and providing options for data anonymization or on-premise processing for sensitive environments.",Advanced Analytics & Artificial Intelligence (AI/ML),"Data privacy considerations for logged queries or voice input data will be addressed, especially if processed by third-party services.",,,,FALSE,high,
2065,REQ-7-018,Functional,"The system shall use AI capabilities to generate reports that summarize data trends, highlight detected anomalies, and identify key performance indicators (KPIs) and potential operational issues from OPC and related data sources.",Advanced Analytics & Artificial Intelligence (AI/ML),"Generates reports based on data trends and anomalies. Uses AI to create customized reports, highlighting KPIs and issues.",,,,FALSE,high,
2066,REQ-7-019,Functional,"The system shall provide a user interface for authorized users to create and customize report templates, allowing selection of data sources (OPC tags, historical data, AI model outputs), KPIs, chart types, and branding elements (e.g., logos, color schemes). Data models for report inputs shall be clearly defined, and the system shall implement data validation rules for these inputs.",Advanced Analytics & Artificial Intelligence (AI/ML),"Users will have options to customize report templates, including selecting data sources, KPIs, chart types, and branding elements. Data validation rules for inputs to report generation will be implemented.",,,,FALSE,high,
2067,REQ-7-020,Functional,"The system shall support scheduled (e.g., daily, weekly) and event-triggered generation of AI-driven reports. Reports shall be exportable in PDF, Excel, and HTML formats. The system shall support report distribution via email, download from the web UI, and saving to configured network locations. Data retention policies for generated reports shall be configurable by administrators.",Advanced Analytics & Artificial Intelligence (AI/ML),"Supports scheduled or event-triggered reporting in various formats (e.g., PDF, Excel, HTML). Reports can be distributed via multiple channels. Data retention policies for generated reports will be configurable.",,,,FALSE,high,
2068,REQ-7-021,Technical,"The server-side application component shall host backend services for AI-driven report generation, utilizing specified reporting libraries or tools (e.g., QuestPDF, ClosedXML for .NET). The system may also support integration with external Business Intelligence (BI) platforms for advanced reporting capabilities.",Advanced Analytics & Artificial Intelligence (AI/ML),"Backend services for AI and reporting will be part of the server-side application component, utilizing reporting generation libraries or tools (e.g., QuestPDF, ClosedXML for .NET, or integration with BI platforms).",,,,FALSE,medium,
2069,REQ-7-022,Functional,"The system shall support version control and archiving for generated reports, particularly those designated as containing regulatory compliance data, adhering to configured data retention policies. The system shall integrate with RBAC to manage distribution lists and access permissions for sensitive reports. The system shall provide mechanisms to support customer-defined workflows for validation and sign-off of AI-generated reports before official dissemination.",Advanced Analytics & Artificial Intelligence (AI/ML),Business Rule: All automated reports containing regulatory compliance data must be version-controlled and archived. Business Rule: The distribution list and access permissions for sensitive reports must be managed. Business Rule: A validation and sign-off process may be required for certain types of AI-generated reports.,,,,FALSE,medium,
2070,REQ-8-001,Functional,"The system shall execute lightweight AI models on designated edge devices to process data locally. It shall be compatible with specified edge hardware including NVIDIA Jetson, Raspberry Pi, and industrial PCs. The system must support AI model deployment using TensorFlow Lite, ONNX Runtime, NVIDIA Triton Inference Server for edge, and Azure IoT Edge ML modules. Execution shall adhere to defined resource constraints, including maximum model size and target inference latency for specific hardware.",External System Integration & Edge Capabilities,"Runs lightweight AI models on edge devices to process data locally, reducing bandwidth and latency. Compatible with edge hardware like NVIDIA Jetson, Raspberry Pi, or industrial PCs. Resource constraints for edge AI models (e.g., maximum model size, target inference latency on specified hardware) will be defined. Frameworks for edge AI deployment (e.g., TensorFlow Lite, ONNX Runtime, NVIDIA Triton Inference Server for edge, Azure IoT Edge ML modules) will be supported.",,,,FALSE,high,
2071,REQ-8-002,Functional,"The system shall perform data validation on edge-sourced data prior to processing or queuing. It shall use secure communication protocols (MQTT over TLS, HTTPS) for edge device management, model deployment, and data synchronization. Edge components must support offline operation for a user-configurable duration, securely queuing data and model outputs. Queued data must be synchronized with the central server upon connectivity restoration, with mechanisms to handle data conflicts or inconsistencies.",External System Integration & Edge Capabilities,"Data validation will be performed on edge-sourced data before processing or queuing. Secure communication protocols (e.g., MQTT over TLS, HTTPS) will be used for edge device management, model deployment, and data synchronization with the central server. Edge components will support offline operation for a configurable duration, queuing data and model outputs for synchronization with the central server when connectivity is restored; data security measures for queued data on edge devices will be implemented.",,,,FALSE,high,
2072,REQ-8-003,Functional,"The system shall provide remote management capabilities for edge devices, including secure deployment of new or updated AI models, secure software updates, and secure remote configuration changes.",External System Integration & Edge Capabilities,"Remote management capabilities will include secure deployment of new/updated AI models, software updates, and configuration changes to edge devices.",,,,FALSE,medium,
2073,REQ-8-004,Functional,"The system shall connect to specified IoT platforms (AWS IoT, Azure IoT, Google Cloud IoT) for extended functionality. It must support standard IoT communication protocols including MQTT, AMQP, and HTTPS. Data exchange shall utilize standard serialization formats such as JSON or Protocol Buffers (Protobuf).",External System Integration & Edge Capabilities,"Connects to IoT ecosystems for extended functionality. Supports AWS IoT, Azure IoT, and Google Cloud IoT for cloud-based analytics, storage, and visualization, using standard IoT protocols like MQTT, AMQP, or HTTPS and data serialization formats like JSON or Protobuf.",,,,FALSE,high,
2074,REQ-8-005,Functional,"The system shall provide configurable data mapping and transformation rules to align OPC data with target IoT platform schemas. It must implement data validation for data received from IoT platforms. Secure device provisioning and credential management for IoT platform communication shall be supported. Bi-directional communication between the OPC client and IoT platforms must be supported. Integrations shall implement robust error handling, retry mechanisms, circuit breaker patterns, and fallback strategies.",External System Integration & Edge Capabilities,"The system will provide flexible data mapping and transformation capabilities, with clearly defined rules, to align OPC data structures with the schemas required by target IoT platforms. Data validation for data received from IoT platforms will be implemented. Secure device provisioning and credential management for communication with IoT platforms will be supported... Bi-directional communication will be supported... Robust error handling, retry mechanisms, circuit breaker patterns, and fallback strategies will be implemented for these integrations.",,,,FALSE,high,
2075,REQ-8-006,Functional,"The system shall integrate with specified AR devices (HoloLens, AR-enabled tablets/smartphones) to overlay real-time OPC data onto physical machinery. It must support AR visualizations including numerical readouts, historical trend charts, and status indicators. AR interaction methods shall include gaze and standard mobile touch gestures, with optional support for voice commands. The system shall support AR applications developed using Unity (with MRTK or Vuforia), Unreal Engine, or native ARCore/ARKit. Real-time data shall be securely streamed to AR applications via WebSockets or a dedicated secure API endpoint.",External System Integration & Edge Capabilities,"Integrates with AR devices (e.g., HoloLens, AR-enabled tablets/smartphones) to overlay real-time data on machinery... AR visualizations will include options for displaying data as numerical readouts, historical trend charts, status indicators... Interaction methods in AR will support gaze, standard mobile touch gestures... and potentially voice commands... AR development will utilize platforms/SDKs like Unity with MRTK or Vuforia, Unreal Engine, or native ARCore/ARKit. Real-time data will be streamed to the AR application via WebSockets or a dedicated secure API endpoint.",,,,FALSE,medium,
2076,REQ-8-007,Functional,"The system shall use a private permissioned blockchain (e.g., Hyperledger Fabric, Ethereum private network) to record critical data exchanges for traceability and compliance. It must provide a configuration interface for users to define 'critical data' based on OPC tags, events, or data change thresholds. Critical data exchanges, after successful OPC server acknowledgement, shall be asynchronously queued and committed to the blockchain via smart contracts, without impacting primary operation latency. The data model for blockchain entries and associated off-chain data (if used) shall be defined.",External System Integration & Edge Capabilities,"Uses a private permissioned blockchain (e.g., Hyperledger Fabric, Ethereum with private network configuration) to record critical data exchanges... A configuration interface will be provided, allowing users to select specific OPC tags, events, or data change thresholds that should be considered 'critical'... Criteria for 'critical data' will be configurable... When such critical data is exchanged... the data designated for blockchain logging... will then be asynchronously queued and committed to the blockchain via smart contracts... without impacting the latency of the primary time-critical operation.",,,,FALSE,medium,
2077,REQ-8-008,Functional,The system shall provide a secure and user-friendly process for authorized users to retrieve blockchain records and verify the integrity of logged critical data. This process must include tools for cryptographic verification of off-chain data against on-chain hashes if off-chain storage is used. Configuration changes related to blockchain integration must be auditable.,External System Integration & Edge Capabilities,"A secure and user-friendly process will be provided for retrieving and verifying data integrity using the blockchain records, potentially including tools for cryptographic verification of off-chain data against on-chain hashes. This configuration itself will be auditable.",,,,FALSE,medium,
2078,REQ-8-009,Functional,"The system shall integrate voice recognition services (including specified cloud-based and on-device/local options) for hands-free client control and data querying. It must support specified languages (initially English) and a documented command grammar and scope. Clear feedback (visual or audio) shall be provided for voice commands. The system shall allow users to define custom voice commands or aliases. Data privacy for voice commands and transcriptions must be ensured, especially if using third-party services. Integration with voice services must include robust error handling, retries, and fallback mechanisms.",External System Integration & Edge Capabilities,"Integrates voice recognition (e.g., Google Cloud Speech-to-Text, Azure Cognitive Service for Speech, or on-device/local network options like Picovoice...) for controlling the client or querying data. Supported languages for voice control will be specified... A defined command grammar and scope will specify the range of voice interactions supported... The system will provide clear feedback for voice commands... Users may have the ability to define custom voice commands or aliases... Data privacy for voice commands... will be ensured. Robust error handling... will be implemented for the integration with external voice recognition services.",,,,FALSE,low,
2079,REQ-8-010,Functional,"The system shall connect to digital twin platforms for simulation and testing, adhering to standards such as AAS, DTDL, or OPC UA for Digital Twin integration where applicable. It must support bi-directional data flow, including feeding real-time OPC data to the digital twin and receiving setpoints/commands from the twin for the OPC client. Configurable and documented data mapping/transformation rules between OPC and Digital Twin models shall be provided. The system must perform data validation for data received from Digital Twin platforms.",External System Integration & Edge Capabilities,"Connects to digital twins for simulation and testing... Interaction will adhere to standards or protocols like Asset Administration Shell (AAS), Digital Twin Definition Language (DTDL), or OPC UA for Digital Twin integration... The scope of interaction will include bi-directional data flow: feeding real-time OPC data to the digital twin and potentially receiving setpoints or commands from the twin back to the OPC client... Data mapping and transformation rules between OPC data models and Digital Twin models will be configurable and documented. Data validation for data received from Digital Twin platforms will be implemented.",,,,FALSE,medium,
2080,REQ-8-011,NonFunctional,"The system shall allow configuration of data synchronization frequency between the OPC client and the digital twin. It must support versioning of digital twin models, ensuring compatibility or providing clear guidance for interfacing with different versions. Secure communication channels and robust authentication mechanisms shall be used for all data exchange with digital twin platforms.",External System Integration & Edge Capabilities,Data synchronization frequency between the OPC client and the digital twin will be configurable... The system will support versioning of digital twin models and ensure compatibility or provide clear guidance when interfacing with different twin versions. Secure communication channels and authentication mechanisms will be used when exchanging data with digital twin platforms.,,,,FALSE,medium,
2081,REQ-9-001,Functional,The system shall implement Role-Based Access Control (RBAC) to manage user access levels and support concurrent users. User management shall be configurable to use either a centralized Identity Provider (IdP) via OAuth 2.0/OpenID Connect or an internal user management system.,"Commercialization, Support & Maintenance","Implements RBAC to control access levels, supporting concurrent users, managed via the centralized IdP or an internal user management system.",,,,FALSE,high,
2082,REQ-9-002,Functional,"The system shall provide a set of predefined default user roles (e.g., Administrator, Engineer, Operator, Viewer) with appropriate, documented permission sets. The system shall allow administrators to customize these default roles and create new custom roles by assigning specific permissions. A clear data model for user roles and permissions shall be defined and documented.","Commercialization, Support & Maintenance","The system will provide a set of predefined default roles (e.g., Administrator, Engineer, Operator, Viewer) with typical permission sets, which can be customized. The data model for user roles and permissions will be defined.",,,,FALSE,high,
2083,REQ-9-003,Functional,"The system shall log all user management actions, including user account creation, deletion, status changes (e.g., enable/disable), role assignments/unassignments, and permission modifications, in a secure and auditable trail. Audit logs shall include timestamp, acting user, affected user, action performed, and outcome.","Commercialization, Support & Maintenance","All user management actions (creation, deletion, role changes, permission modifications) will be logged in an audit trail.",,,,FALSE,high,
2084,REQ-9-004,Functional,"The system shall provide a web-based centralized management dashboard, served by the server-side application component. This dashboard shall enable authorized administrators to monitor the status and performance of, and comprehensively configure, all managed OPC client instances across different sites, including client instances deployed headlessly.","Commercialization, Support & Maintenance","Provides a web-based dashboard, served by the server-side application component of the hybrid architecture, for monitoring and comprehensively configuring clients across sites. This includes the ability to fully manage all client instances, including those deployed headlessly.",,,,FALSE,high,
2085,REQ-9-005,Functional,"The centralized management dashboard shall support bulk operations for configuring multiple client instances simultaneously (e.g., deploying standard configurations, initiating software updates). The dashboard shall display Key Performance Indicators (KPIs) summarizing the overall health, connectivity, and performance of all managed client instances, with documented data sources for these KPIs. All administrative functions available through the dashboard shall be clearly documented in the Administrator Guide.","Commercialization, Support & Maintenance","The centralized dashboard will support bulk operations for configuring multiple client instances simultaneously (e.g., deploying standard configurations, updating software). Key Performance Indicators (KPIs) summarizing the overall health, connectivity, and performance of all managed client instances will be prominently displayed on the centralized dashboard, with defined data sources for these KPIs. Administrative functions available through this interface will be clearly documented.",,,,FALSE,high,
2086,REQ-9-006,Functional,"The system shall support flexible licensing models, including options such as per-user, per-site, or subscription-based. The system shall enable tiered features, where available functionality is determined by the acquired license level.","Commercialization, Support & Maintenance","Includes per-user, per-site, or subscription-based models, with tiered features.",,,,FALSE,high,
2087,REQ-9-007,Technical,"License management, including activation, validation, and enforcement, shall be handled by a dedicated licensing system. This system may be a commercial off-the-shelf solution or a proprietary system incorporating license key generation and validation server capabilities.","Commercialization, Support & Maintenance","License management will be handled by a dedicated licensing system (e.g., a commercial solution like Flexera or a proprietary system with a license key generation and validation server).",,,,FALSE,high,
2088,REQ-9-008,Functional,"The licensing system shall support a configurable grace period, allowing continued system operation for a limited time in case of temporary license validation issues, with clear notifications provided to administrators regarding the issue and remaining grace period. The system shall also support a secure offline license activation and validation mechanism for environments without persistent internet access.","Commercialization, Support & Maintenance","The licensing system will define a grace period for continued operation in case of temporary license validation issues, with clear notifications to administrators. For environments without internet access, an offline license activation and validation mechanism will be supported.",,,,FALSE,high,
2089,REQ-9-009,NonFunctional,"The system shall be delivered with comprehensive technical documentation sets, including at a minimum: User Manual, Administrator Guide, Installation Guide, API Documentation (for all public APIs), Troubleshooting Guide, and Release Notes for each version. This documentation shall be hosted on a readily accessible platform (e.g., ReadtheDocs, Confluence, or a dedicated custom portal).","Commercialization, Support & Maintenance","Includes documentation (User Manual, Administrator Guide, Installation Guide, API Documentation, Troubleshooting Guide, Release Notes) hosted on a platform like ReadtheDocs, Confluence, or a custom portal.",,,,FALSE,high,
2090,REQ-9-010,NonFunctional,"Technical support services, including access to tutorials, shall be provided as part of the license agreement. Support requests shall be managed through a designated support ticketing system (e.g., Jira Service Desk, Zendesk, Freshdesk). Service Level Agreements (SLAs) for technical support, detailing response times and target resolution times based on issue severity, shall be clearly defined and communicated.","Commercialization, Support & Maintenance","Includes documentation... tutorials, and 24/7 support as part of the license, managed through a support ticketing system (e.g., Jira Service Desk, Zendesk, Freshdesk). Service Level Agreements (SLAs) for technical support, detailing response times and target resolution times based on issue severity, will be clearly defined.",,,,FALSE,high,
2091,REQ-9-011,NonFunctional,"Comprehensive training materials shall be developed and made available in various formats, such as written documentation, video tutorials, and potentially interactive e-learning modules. A detailed training plan shall be created, identifying target audiences (administrators, engineers, operators, maintenance staff), curriculum, delivery methods (e.g., instructor-led, self-paced), and schedule. Plans for post-go-live refreshment training and new feature training shall be established.","Commercialization, Support & Maintenance","Training materials will be available in various formats, including written documentation, video tutorials, and potentially interactive e-learning modules. A detailed training plan, including target audience identification... schedule, will be developed... Post-go-live refreshment training and new feature training will also be planned and budgeted for.",,,,FALSE,high,
2092,REQ-9-012,NonFunctional,"A publicly accessible knowledge base and/or community forum shall be established and maintained to facilitate self-service support and peer-to-peer assistance. A clear policy for scheduled maintenance windows for server-side components, including minimum notification period, typical duration, and expected frequency, shall be defined and communicated to all customers.","Commercialization, Support & Maintenance","A publicly accessible knowledge base and/or community forum will be maintained for self-service support and peer-to-peer assistance. A defined policy for maintenance windows for server-side components (e.g., notification period, typical duration, frequency) will be communicated to customers.",,,,FALSE,medium,
2093,REQ-9-013,NonFunctional,"The system software shall receive regular updates, including new features, security patches, and compatibility improvements. A general release cadence (e.g., major releases annually, minor releases quarterly, patches as needed) shall be established and communicated to customers.","Commercialization, Support & Maintenance","Delivers new features, security patches, and compatibility improvements regularly. A general release cadence will be communicated (e.g., major releases annually, minor releases quarterly, patches as needed).",,,,FALSE,high,
2094,REQ-9-014,Technical,"All source code for the system shall be managed using a distributed version control system (e.g., Git). Code repositories shall be hosted on a secure, managed platform (e.g., GitHub, GitLab, Azure Repos).","Commercialization, Support & Maintenance","Development will use a version control system (e.g., Git) with repositories hosted on platforms like GitHub, GitLab, or Azure Repos.",,,,FALSE,medium,
2095,REQ-9-015,Technical,"A Continuous Integration/Continuous Deployment (CI/CD) pipeline (e.g., using Jenkins, GitLab CI, Azure DevOps, GitHub Actions) shall be implemented to automate the building, comprehensive testing, and deployment of software updates. The testing strategy within the pipeline shall include unit, integration, end-to-end, performance, and security (SAST, DAST) tests. Software updates shall be delivered to customers via a secure mechanism (e.g., package manager repositories, in-app update notifications with secure download links, or direct secure deployment for cloud components).","Commercialization, Support & Maintenance","A CI/CD pipeline will automate building, testing (unit, integration, E2E, performance, security), and deploying updates. Updates will be delivered via a secure mechanism.",,,,FALSE,high,
2096,REQ-9-016,NonFunctional,"A documented and tested rollback strategy shall be in place, allowing administrators to revert the system or its components to a previous stable version in case of critical issues introduced by an update. Each software update shall be accompanied by comprehensive release notes detailing new features, improvements, bug fixes, known issues, and any breaking changes.","Commercialization, Support & Maintenance","A documented rollback strategy will be in place for reverting to a previous stable version in case of critical issues with an update. Comprehensive release notes detailing new features, improvements, bug fixes, and any breaking changes will accompany each update.",,,,FALSE,high,
2097,REQ-9-017,NonFunctional,"The server-side application components of the system shall have a defined overall system availability target (e.g., 99.9% uptime, excluding scheduled maintenance windows). Mechanisms shall be in place to monitor adherence to this availability target.","Commercialization, Support & Maintenance","Overall system availability targets (e.g., 99.9% for server-side components, excluding scheduled maintenance) will be defined and monitored.",,,,FALSE,high,
2098,REQ-9-018,Functional,"The system shall provide reporting capabilities that allow administrators to generate reports listing user accounts, their assigned roles, and the permissions associated with those roles. These reports are intended to facilitate periodic user access reviews by customer organizations.","Commercialization, Support & Maintenance","Business Rule: User access rights and roles must be reviewed periodically (e.g., quarterly) by department managers or system owners to ensure they align with current job responsibilities (principle of least privilege).",,,,FALSE,medium,
